# ğŸ“˜ DocumentaÃ§Ã£o do Projeto â€“ LLM com  Banco de Dados Vetorial

Este projeto implementa um **Banco de Dados Vetorial** utilizando a biblioteca LangChain,
com suporte a embeddings da OpenAI e armazenamento no ChromaDB. O objetivo usuÃ¡rios faÃ§am pperguntas ao banco de conhecimento em arquivos pdf e LLM retorna 
a resposta . O fluxo Ã© dividido em dois mÃ³dulos principais:

1. **Criardb.py** â€“ ResponsÃ¡vel por:
   - Carregar documentos PDF da pasta `base/`
   - Dividir textos em pedaÃ§os menores (chunks)
   - Converter chunks em embeddings vetoriais
   - Salvar no banco vetorial `db/`

2. **main.py** â€“ ResponsÃ¡vel por:
   - Receber perguntas do usuÃ¡rio
   - Gerar embedding da pergunta
   - Buscar chunks relevantes no banco vetorial
   - Enviar para um modelo de linguagem (OpenAI) responder

---

## ğŸ”¹ Conceitos-Chave
- **Banco Vetorial**: armazena vetores (representaÃ§Ãµes numÃ©ricas) de textos.
- **Embeddings**: transformam textos em vetores para comparaÃ§Ã£o semÃ¢ntica.
- **Chunks**: divisÃ£o de textos longos em pedaÃ§os menores para melhor desempenho.
- **LangChain + ChromaDB + OpenAI**: integraÃ§Ã£o para criar, armazenar e consultar embeddings.

---

## ğŸš€ Fluxo do Sistema
1. Criar DB â†’ carregar PDFs â†’ dividir â†’ gerar embeddings â†’ salvar.
2. Main â†’ receber pergunta â†’ gerar embedding da pergunta â†’ buscar no banco â†’ IA responde.

---

## ğŸ“¦ DependÃªncias
Instalar pacotes necessÃ¡rios:
```bash
pip install python-dotenv langchain langchain-openai langchain-community langchain-chroma chromadb openai pypdf
```

---

## ğŸ’¡ Exemplo de Uso
1. Coloque seus arquivos PDF na pasta `base/`
2. Crie um arquivo .env e digite OPENAI_API_KEY = cole sua chave api da openai. 
3. Execute `Criardb.py` para criar o banco
4. Execute `main.py` e faÃ§a perguntas no terminal
